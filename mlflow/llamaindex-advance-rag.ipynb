{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "from pathlib import Path\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, Document, StorageContext, load_index_from_storage\n",
    "from llama_index.core.node_parser import SentenceWindowNodeParser\n",
    "from llama_index.core.indices.postprocessor import MetadataReplacementPostProcessor, SentenceTransformerRerank\n",
    "from llama_index.core.response.notebook_utils import display_response\n",
    "from llama_index.core.settings import Settings\n",
    "\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path('..', 'data')\n",
    "SENTENCE_INDEX_PATH = Path(DATA_DIR, \"sentence_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(model_name=\"models/gpt4o-mini\", temperature=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/08 20:55:36 INFO mlflow.tracking.fluent: Experiment with name 'LLamaIndex RAG Tracing' does not exist. Creating a new experiment.\n"
     ]
    }
   ],
   "source": [
    "# Using a local MLflow tracking server\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "mlflow.set_experiment(\"LLamaIndex RAG Tracing\")\n",
    "\n",
    "mlflow.llama_index.autolog(\n",
    "    silent=True,\n",
    "    log_traces=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Index Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "documents = SimpleDirectoryReader(input_files=[Path(DATA_DIR, \"eBook-How-to-Build-a-Career-in-AI.pdf\")]).load_data()\n",
    "\n",
    "# Convert into a Document\n",
    "document = Document(text=\"\\n\\n\".join([doc.text for doc in documents]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Sentence Index\n",
    "## Create the sentence window node parser w/ default settings\n",
    "node_parser = SentenceWindowNodeParser.from_defaults(\n",
    "    window_size=3,\n",
    "    window_metadata_key=\"window\",\n",
    "    original_text_metadata_key=\"original_text\",\n",
    ")\n",
    "\n",
    "## Llama-Index Global Settings\n",
    "Settings.llm = llm\n",
    "# Settings.embed_model = \"local:BAAI/bge-small-en-v1.5\"\n",
    "Settings.node_parser = node_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Sentence Index\n"
     ]
    }
   ],
   "source": [
    "# Create the sentence index\n",
    "# if an index file exist, then it will load it\n",
    "# if not, it will rebuild it\n",
    "\n",
    "if not SENTENCE_INDEX_PATH.exists():\n",
    "    print(\"Building Sentence Index\")\n",
    "    sentence_index = VectorStoreIndex.from_documents([document], embed_model = \"local:BAAI/bge-small-en-v1.5\")\n",
    "    sentence_index.storage_context.persist(persist_dir=SENTENCE_INDEX_PATH)\n",
    "\n",
    "else:\n",
    "    print(\"Loading Sentence Index\")\n",
    "    sentence_index = load_index_from_storage(StorageContext.from_defaults(persist_dir=SENTENCE_INDEX_PATH), embed_model = \"local:BAAI/bge-small-en-v1.5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post-Processing and ReRanking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instead of passing only the retrieved sentence, we pass a window of sentences - Sentence Window Retrieval\n",
    "postproc = MetadataReplacementPostProcessor(target_metadata_key=\"window\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rerank the sentences using a Sentence Transformer\n",
    "rerank = SentenceTransformerRerank(top_n=2, model=\"BAAI/bge-reranker-base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the query engine\n",
    "sentence_window_engine = sentence_index.as_query_engine(similarity_top_k=6, node_postprocessors=[postproc, rerank])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**`Final Response:`** The keys to building a career in AI involve learning foundational technical skills, working on projects, finding a job, and being part of a supportive community."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "window_response = sentence_window_engine.query(\n",
    "    \"What are the keys to building a career in AI?\"\n",
    ")\n",
    "display_response(window_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Optional) Logging LlamaIndex Model to MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/08 20:56:15 WARNING mlflow.llama_index: The `engine_type` argument is ignored when saving a non-index object.\n",
      "2024/11/08 20:56:15 INFO mlflow.llama_index.serialize_objects: API key(s) will be removed from the global Settings object during serialization to protect against key leakage. At inference time, the key(s) must be passed as environment variables.\n",
      "2024/11/08 20:56:15 INFO mlflow.llama_index.serialize_objects: API key(s) will be removed from the global Settings object during serialization to protect against key leakage. At inference time, the key(s) must be passed as environment variables.\n",
      "2024/11/08 20:56:52 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/11/08 20:56:52 INFO mlflow.tracking._tracking_service.client: üèÉ View run defiant-kite-604 at: http://localhost:5000/#/experiments/785024666113594312/runs/1ff10b847e714e4f988c4c834c172558.\n",
      "2024/11/08 20:56:52 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: http://localhost:5000/#/experiments/785024666113594312.\n"
     ]
    }
   ],
   "source": [
    "query_engine_path = \"./llamaindex-adv-rag-model.py\"\n",
    "\n",
    "with mlflow.start_run():\n",
    "    model_info = mlflow.llama_index.log_model(\n",
    "        llama_index_model=query_engine_path,\n",
    "        artifact_path=\"rag-index-query\",\n",
    "        engine_type=\"query\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'runs:/1ff10b847e714e4f988c4c834c172558/rag-index-query'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_info.model_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b21c8ffc0fd6400382e0793d77ec0d2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the model and run inference\n",
    "sentence_window_query_engine = mlflow.llama_index.load_model(model_uri=model_info.model_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**`Final Response:`** The keys to building a career in AI involve learning foundational technical skills, working on projects, finding a job, and being part of a supportive community."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "window_response = sentence_window_query_engine.query(\"What are the keys to building a career in AI?\")\n",
    "display_response(window_response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLMObs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
