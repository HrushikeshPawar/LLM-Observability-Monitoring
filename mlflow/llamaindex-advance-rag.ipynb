{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, Document, StorageContext, load_index_from_storage\n",
    "from llama_index.core.node_parser import SentenceWindowNodeParser\n",
    "from llama_index.core.memory import ChatMemoryBuffer\n",
    "from llama_index.core.indices.postprocessor import MetadataReplacementPostProcessor, SentenceTransformerRerank\n",
    "from llama_index.core.response.notebook_utils import display_response\n",
    "from llama_index.core.settings import Settings\n",
    "\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path('..', 'data')\n",
    "SENTENCE_INDEX_PATH = Path(DATA_DIR, \"sentence_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(model_name=\"models/gpt4o-mini\", temperature=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/11 14:01:30 INFO mlflow.tracking.fluent: Experiment with name 'LLamaIndex RAG Tracing' does not exist. Creating a new experiment.\n"
     ]
    }
   ],
   "source": [
    "# Using a local MLflow tracking server\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "mlflow.set_experiment(\"LLamaIndex RAG Tracing\")\n",
    "\n",
    "mlflow.llama_index.autolog(\n",
    "    silent=True,\n",
    "    log_traces=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Index Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "documents = SimpleDirectoryReader(input_files=[Path(DATA_DIR, \"eBook-How-to-Build-a-Career-in-AI.pdf\")]).load_data()\n",
    "\n",
    "# Convert into a Document\n",
    "document = Document(text=\"\\n\\n\".join([doc.text for doc in documents]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Sentence Index\n",
    "## Create the sentence window node parser w/ default settings\n",
    "node_parser = SentenceWindowNodeParser.from_defaults(\n",
    "    window_size=3,\n",
    "    window_metadata_key=\"window\",\n",
    "    original_text_metadata_key=\"original_text\",\n",
    ")\n",
    "\n",
    "## Llama-Index Global Settings\n",
    "Settings.llm = llm\n",
    "# Settings.embed_model = \"local:BAAI/bge-small-en-v1.5\"\n",
    "Settings.node_parser = node_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Sentence Index\n"
     ]
    }
   ],
   "source": [
    "# Create the sentence index\n",
    "# if an index file exist, then it will load it\n",
    "# if not, it will rebuild it\n",
    "\n",
    "if not SENTENCE_INDEX_PATH.exists():\n",
    "    print(\"Building Sentence Index\")\n",
    "    sentence_index = VectorStoreIndex.from_documents([document], embed_model = \"local:BAAI/bge-small-en-v1.5\")\n",
    "    sentence_index.storage_context.persist(persist_dir=SENTENCE_INDEX_PATH)\n",
    "\n",
    "else:\n",
    "    print(\"Loading Sentence Index\")\n",
    "    sentence_index = load_index_from_storage(StorageContext.from_defaults(persist_dir=SENTENCE_INDEX_PATH), embed_model = \"local:BAAI/bge-small-en-v1.5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post-Processing and ReRanking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instead of passing only the retrieved sentence, we pass a window of sentences - Sentence Window Retrieval\n",
    "postproc = MetadataReplacementPostProcessor(target_metadata_key=\"window\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rerank the sentences using a Sentence Transformer\n",
    "rerank = SentenceTransformerRerank(top_n=2, model=\"BAAI/bge-reranker-base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the query engine\n",
    "sentence_window_engine = sentence_index.as_query_engine(similarity_top_k=6, node_postprocessors=[postproc, rerank])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**`Final Response:`** The keys to building a career in AI involve learning foundational technical skills, working on projects, finding a job, and being part of a supportive community."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "window_response = sentence_window_engine.query(\n",
    "    \"What are the keys to building a career in AI?\"\n",
    ")\n",
    "display_response(window_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**`Final Response:`** The three key steps of career growth in the field of AI are learning foundational technical skills, working on projects, and finding a job. Learning foundational technical skills involves acquiring the necessary knowledge and expertise in AI. Working on projects allows individuals to apply their skills in practical settings and gain hands-on experience. Finding a job involves securing a position in the field of AI, which can be facilitated by showcasing one's skills and experience to potential employers."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "window_response = sentence_window_engine.query(\n",
    "    \"According to the text, what are the three key steps of career growth in the field of AI? Provide a brief explanation of each step.\"\n",
    ")\n",
    "display_response(window_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Chat engine\n",
    "memory = ChatMemoryBuffer.from_defaults(token_limit=5000)\n",
    "sentence_window_chat_engine = sentence_index.as_chat_engine(\n",
    "    chat_mode=\"context\",\n",
    "    memory=memory,\n",
    "    system_prompt=(\n",
    "        \"You are a chatbot, able to have normal interactions, as well as talk\"\n",
    "        \" about a book \\\"How to Build a Career in AI\\\" by Andrew Ng.\"\n",
    "    ),\n",
    "    similarity_top_k=6,\n",
    "    node_postprocessors=[postproc, rerank]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**`Final Response:`** The scenario planning exercise mentioned in the context of the Covid-19 pandemic involved imagining different recovery scenarios and making plans for each case. In this exercise, the individual considered three possible scenarios: a quick recovery (three months), a medium recovery (one year), and a slow recovery (two years) from Covid-19. By creating plans for managing each scenario, the individual was able to prioritize actions and decisions based on the potential outcomes. This exercise helped in regaining a sense of control and preparedness in the face of uncertainty during the pandemic."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "window_response = sentence_window_chat_engine.chat(\n",
    "    \"Explain the scenario planning exercise mentioned in the context of the Covid-19 pandemic.\"\n",
    ")\n",
    "display_response(window_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**`Final Response:`** The scenario planning method can be applied to personal life situations such as job hunting or exam preparation by considering different possible outcomes and creating plans for each scenario. For example, if you are unsure about passing an exam, getting a job offer, or being granted a visa, you can write out what you would do in each of the likely scenarios. By thinking through the possibilities and following through on plans for each outcome, you can navigate these situations more effectively and reduce stress associated with uncertainty. This approach helps you prepare for different possibilities and take proactive steps to achieve your goals, no matter what the future brings."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "window_response = sentence_window_chat_engine.chat(\n",
    "    \"How can this method be applied to personal life situations such as job hunting or exam preparation?\"\n",
    ")\n",
    "display_response(window_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Optional) Logging LlamaIndex Model to MLFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/11 14:01:59 WARNING mlflow.llama_index: The `engine_type` argument is ignored when saving a non-index object.\n",
      "2024/11/11 14:01:59 INFO mlflow.llama_index.serialize_objects: API key(s) will be removed from the global Settings object during serialization to protect against key leakage. At inference time, the key(s) must be passed as environment variables.\n",
      "2024/11/11 14:01:59 INFO mlflow.llama_index.serialize_objects: API key(s) will be removed from the global Settings object during serialization to protect against key leakage. At inference time, the key(s) must be passed as environment variables.\n",
      "2024/11/11 14:02:14 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/11/11 14:02:14 INFO mlflow.tracking._tracking_service.client: üèÉ View run vaunted-hound-796 at: http://localhost:5000/#/experiments/334194126917619707/runs/f55d2dd2281c4e15b5bab54df5805612.\n",
      "2024/11/11 14:02:14 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: http://localhost:5000/#/experiments/334194126917619707.\n"
     ]
    }
   ],
   "source": [
    "query_engine_path = \"./llamaindex-adv-rag-model.py\"\n",
    "\n",
    "with mlflow.start_run():\n",
    "    model_info = mlflow.llama_index.log_model(\n",
    "        llama_index_model=query_engine_path,\n",
    "        artifact_path=\"rag-index-query\",\n",
    "        engine_type=\"query\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c18950406f0841c0aee492faa482dfd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the model and run inference\n",
    "sentence_window_query_engine = mlflow.llama_index.load_model(model_uri=model_info.model_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**`Final Response:`** The keys to building a career in AI involve learning foundational technical skills, working on projects, finding a job, and being part of a supportive community."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "window_response = sentence_window_query_engine.query(\"What are the keys to building a career in AI?\")\n",
    "display_response(window_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**`Final Response:`** The three key steps of career growth in the field of AI are learning foundational technical skills, working on projects, and finding a job. Learning foundational technical skills involves acquiring the necessary knowledge and expertise in AI. Working on projects allows individuals to apply their skills in practical scenarios and gain hands-on experience. Finding a job involves securing a position in the AI field, which can be facilitated by showcasing one's skills and experience to potential employers."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "window_response = sentence_window_engine.query(\n",
    "    \"According to the text, what are the three key steps of career growth in the field of AI? Provide a brief explanation of each step.\"\n",
    ")\n",
    "display_response(window_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLMObs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
