{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to /home/hrushikesh/.pyenv/v\n",
      "[nltk_data]     ersions/LLMObs/lib/python3.12/site-\n",
      "[nltk_data]     packages/llama_index/core/_static/nltk_cache...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "from pathlib import Path\n",
    "from llama_index.llms.gemini import Gemini\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, Document, StorageContext, load_index_from_storage, ServiceContext\n",
    "from llama_index.core.node_parser import SentenceWindowNodeParser\n",
    "from llama_index.core.indices.postprocessor import MetadataReplacementPostProcessor, SentenceTransformerRerank\n",
    "from llama_index.core.response.notebook_utils import display_response\n",
    "\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path('..', 'data')\n",
    "SENTENCE_INDEX_PATH = Path(DATA_DIR, \"sentence_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Gemini(model_name=\"models/gemini-1.5-flash-002\", temperature=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/08 16:04:20 INFO mlflow.tracking.fluent: Experiment with name 'LLamaIndex RAG Tracing' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/886422159020597810', creation_time=1731062060735, experiment_id='886422159020597810', last_update_time=1731062060735, lifecycle_stage='active', name='LLamaIndex RAG Tracing', tags={}>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using a local MLflow tracking server\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "mlflow.set_experiment(\"LLamaIndex RAG Tracing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Index Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "documents = SimpleDirectoryReader(input_files=[Path(DATA_DIR, \"eBook-How-to-Build-a-Career-in-AI.pdf\")]).load_data()\n",
    "\n",
    "# Convert into a Document\n",
    "document = Document(text=\"\\n\\n\".join([doc.text for doc in documents]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Sentence Index\n",
    "## Create the sentence window node parser w/ default settings\n",
    "node_parser = SentenceWindowNodeParser.from_defaults(\n",
    "    window_size=3,\n",
    "    window_metadata_key=\"window\",\n",
    "    original_text_metadata_key=\"original_text\",\n",
    ")\n",
    "\n",
    "## Sentence Context Model\n",
    "sentence_context = ServiceContext.from_defaults(\n",
    "    llm=llm,\n",
    "    embed_model=\"local:BAAI/bge-small-en-v1.5\",\n",
    "    # embed_model=\"local:BAAI/bge-large-en-v1.5\"\n",
    "    node_parser=node_parser,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the sentence index\n",
    "# if an index file exist, then it will load it\n",
    "# if not, it will rebuild it\n",
    "\n",
    "if not SENTENCE_INDEX_PATH.exists():\n",
    "    sentence_index = VectorStoreIndex.from_documents([document], service_context=sentence_context)\n",
    "    sentence_index.storage_context.persist(persist_dir=SENTENCE_INDEX_PATH)\n",
    "\n",
    "else:\n",
    "    sentence_index = load_index_from_storage(StorageContext.from_defaults(persist_dir=SENTENCE_INDEX_PATH), service_context=sentence_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post-Processing and ReRanking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instead of passing only the retrieved sentence, we pass a window of sentences - Sentence Window Retrieval\n",
    "postproc = MetadataReplacementPostProcessor(target_metadata_key=\"window\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rerank the sentences using a Sentence Transformer\n",
    "rerank = SentenceTransformerRerank(top_n=2, model=\"BAAI/bge-reranker-base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the query engine\n",
    "sentence_window_engine = sentence_index.as_query_engine(similarity_top_k=6, node_postprocessors=[postproc, rerank])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Log the query engine to mlfow\n",
    "# with mlflow.start_run():\n",
    "#     model_info = mlflow.llama_index.log_model(\n",
    "#         sentence_window_engine,\n",
    "#         artifact_path=\"rag-index-query\",\n",
    "#         engine_type=\"query\",\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.llama_index.autolog(\n",
    "    silent=True,\n",
    "    log_traces=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_response = sentence_window_engine.query(\n",
    "    \"What are the keys to building a career in AI?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**`Final Response:`** The keys to building a career in AI include learning foundational technical skills, working on projects, and finding a job, all while being part of a supportive community."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_response(window_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Optional) Logging LlamaIndex Model to MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/08 16:05:00 WARNING mlflow.llama_index: The `engine_type` argument is ignored when saving a non-index object.\n",
      "2024/11/08 16:05:00 INFO mlflow.llama_index.serialize_objects: API key(s) will be removed from the global Settings object during serialization to protect against key leakage. At inference time, the key(s) must be passed as environment variables.\n",
      "2024/11/08 16:05:00 INFO mlflow.llama_index.serialize_objects: API key(s) will be removed from the global Settings object during serialization to protect against key leakage. At inference time, the key(s) must be passed as environment variables.\n",
      "2024/11/08 16:05:36 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/11/08 16:05:37 INFO mlflow.tracking._tracking_service.client: üèÉ View run rambunctious-koi-788 at: http://localhost:5000/#/experiments/886422159020597810/runs/a4db4ba1feb14c11a08ad898faa9e665.\n",
      "2024/11/08 16:05:37 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: http://localhost:5000/#/experiments/886422159020597810.\n"
     ]
    }
   ],
   "source": [
    "query_engine_path = \"./llamaindex-adv-rag-model.py\"\n",
    "\n",
    "with mlflow.start_run():\n",
    "    model_info = mlflow.llama_index.log_model(\n",
    "        llama_index_model=query_engine_path,\n",
    "        artifact_path=\"rag-index-query\",\n",
    "        engine_type=\"query\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'runs:/a4db4ba1feb14c11a08ad898faa9e665/rag-index-query'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_info.model_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46492d1c6d204f92a2904c29c89f1451",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the model and run inference\n",
    "sentence_window_query_engine = mlflow.llama_index.load_model(model_uri=model_info.model_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**`Final Response:`** The keys to building a career in AI include learning foundational technical skills, working on projects, and finding a job, all while being part of a supportive community."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "window_response = sentence_window_query_engine.query(\"What are the keys to building a career in AI?\")\n",
    "display_response(window_response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLMObs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
