{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "from pathlib import Path\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path('..', 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new index\n",
    "documents = SimpleDirectoryReader(DATA_DIR).load_data(show_progress=True, num_workers=4)\n",
    "index = VectorStoreIndex.from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using a local MLflow tracking server\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/08 10:00:49 INFO mlflow.llama_index.serialize_objects: API key(s) will be removed from the global Settings object during serialization to protect against key leakage. At inference time, the key(s) must be passed as environment variables.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed744aff5d7745c9b4e6a1984c70c329",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/08 10:01:13 INFO mlflow.tracking._tracking_service.client: ðŸƒ View run dapper-yak-192 at: http://localhost:5000/#/experiments/474074094483824798/runs/c6f1ae24497940279fee1410d4bb20cd.\n",
      "2024/11/08 10:01:13 INFO mlflow.tracking._tracking_service.client: ðŸ§ª View experiment at: http://localhost:5000/#/experiments/474074094483824798.\n",
      "2024/11/08 10:01:13 INFO mlflow.tracking._tracking_service.client: ðŸ§ª View experiment at: http://localhost:5000/#/experiments/474074094483824798.\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_experiment(\"LLamaIndex Tracing\")\n",
    "\n",
    "with mlflow.start_run():\n",
    "    model_info = mlflow.llama_index.log_model(\n",
    "        index,\n",
    "        artifact_path=\"index\",\n",
    "        engine_type=\"chat\",\n",
    "        input_example=\"What did the author do growing up?\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'runs:/c6f1ae24497940279fee1410d4bb20cd/index'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_info.model_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76ed551371d74536bbc3147f7041bebb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first program the author wrote was on the IBM 1401 using an early version of Fortran.\n"
     ]
    }
   ],
   "source": [
    "model = mlflow.pyfunc.load_model(model_info.model_uri)\n",
    "\n",
    "response = model.predict(\"What was the first program the author wrote?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The author felt puzzled by the first program they wrote on the IBM 1401 in 9th grade. They couldn't figure out what to do with it and realized there wasn't much they could have done with it due to the limitations of input options. The author mentioned that the programs they wrote on the IBM 1401 couldn't have done much, and their clearest memory was when they learned that programs could fail to terminate, which was a social and technical error on a machine without time-sharing.\n"
     ]
    }
   ],
   "source": [
    "# The chat engine keeps track of the conversation history\n",
    "response = model.predict(\"How did the author feel about it?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enble Tracing\n",
    "mlflow.llama_index.autolog(\n",
    "    silent=True,\n",
    "    log_traces=True,\n",
    "    # log_models=True,\n",
    "    # log_model_signatures=True,\n",
    "    # log_input_examples=True,\n",
    ")\n",
    "\n",
    "chat_engine = index.as_chat_engine()\n",
    "response = chat_engine.chat(\"What was the first program the author wrote?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first program the author wrote was on the IBM 1401 using an early version of Fortran.\n"
     ]
    }
   ],
   "source": [
    "print(response.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLMObs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
