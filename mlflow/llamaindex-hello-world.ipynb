{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "from pathlib import Path\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path('..', 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new index\n",
    "documents = SimpleDirectoryReader(DATA_DIR).load_data(show_progress=True, num_workers=4)\n",
    "index = VectorStoreIndex.from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using a local MLflow tracking server\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/08 20:55:43 INFO mlflow.tracking.fluent: Experiment with name 'LLamaIndex Tracing' does not exist. Creating a new experiment.\n",
      "2024/11/08 20:55:47 INFO mlflow.llama_index.serialize_objects: API key(s) will be removed from the global Settings object during serialization to protect against key leakage. At inference time, the key(s) must be passed as environment variables.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5abca4ec8bd4a46b970f53a21b7f403",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/08 20:56:17 INFO mlflow.tracking._tracking_service.client: 🏃 View run victorious-snipe-405 at: http://localhost:5000/#/experiments/372917090010095068/runs/67f9b3da714243428f5f4e52476357b0.\n",
      "2024/11/08 20:56:17 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://localhost:5000/#/experiments/372917090010095068.\n",
      "2024/11/08 20:56:17 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://localhost:5000/#/experiments/372917090010095068.\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_experiment(\"LLamaIndex Tracing\")\n",
    "\n",
    "with mlflow.start_run():\n",
    "    model_info = mlflow.llama_index.log_model(\n",
    "        index,\n",
    "        artifact_path=\"index\",\n",
    "        engine_type=\"chat\",\n",
    "        input_example=\"What did the author do growing up?\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'runs:/67f9b3da714243428f5f4e52476357b0/index'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_info.model_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d2fd4e972f04c1d8637c484daff8e58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first program the author wrote was on the IBM 1401 using an early version of Fortran in 9th grade, around the age of 13 or 14.\n"
     ]
    }
   ],
   "source": [
    "model = mlflow.pyfunc.load_model(model_info.model_uri)\n",
    "\n",
    "response = model.predict(\"What was the first program the author wrote?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The author felt puzzled by the first program they wrote on the IBM 1401 in 9th grade. They couldn't figure out what to do with it and realized there wasn't much they could have done with it due to the limitations of the system. The author mentioned that the programs they wrote on the IBM 1401 couldn't have done much, and their clearest memory was when they learned that it was possible for programs not to terminate.\n"
     ]
    }
   ],
   "source": [
    "# The chat engine keeps track of the conversation history\n",
    "response = model.predict(\"How did the author feel about it?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enble Tracing\n",
    "mlflow.llama_index.autolog(\n",
    "    silent=True,\n",
    "    log_traces=True,\n",
    "    # log_models=True,\n",
    "    # log_model_signatures=True,\n",
    "    # log_input_examples=True,\n",
    ")\n",
    "\n",
    "chat_engine = index.as_chat_engine()\n",
    "response = chat_engine.chat(\"What was the first program the author wrote?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first program the author wrote was on the IBM 1401 using an early version of Fortran in 9th grade, when he was around 13 or 14 years old.\n"
     ]
    }
   ],
   "source": [
    "print(response.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLMObs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
