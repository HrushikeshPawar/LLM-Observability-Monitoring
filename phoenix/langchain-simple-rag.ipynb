{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import phoenix as px\n",
    "\n",
    "from phoenix.otel import register\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from pathlib import Path\n",
    "\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "from langchain.chains.history_aware_retriever import create_history_aware_retriever\n",
    "from langchain.chains.retrieval import create_retrieval_chain\n",
    "from langchain.chains.retrieval_qa.base import RetrievalQA\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
    "\n",
    "from openinference.instrumentation.langchain import LangChainInstrumentor\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (\"GOOGLE_API_KEY\" in os.environ), \"Please set your GOOGLE_API_KEY environment variable.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üåç To view the Phoenix app in your browser, visit http://localhost:6006/\n",
      "üíΩ Your data is being persisted to sqlite:////home/hrushikesh/.phoenix/phoenix.db\n",
      "üìñ For more information on how to use Phoenix, check out https://docs.arize.com/phoenix\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<phoenix.session.session.ThreadSession at 0x7f70acc77e00>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Launch Phoenix\n",
    "import phoenix as px\n",
    "px.launch_app(use_temp_dir=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî≠ OpenTelemetry Tracing Details üî≠\n",
      "|  Phoenix Project: LangChain RAG Tracing\n",
      "|  Span Processor: SimpleSpanProcessor\n",
      "|  Collector Endpoint: localhost:4317\n",
      "|  Transport: gRPC\n",
      "|  Transport Headers: {'user-agent': '****'}\n",
      "|  \n",
      "|  Using a default SpanProcessor. `add_span_processor` will overwrite this default.\n",
      "|  \n",
      "|  `register` has set this TracerProvider as the global OpenTelemetry default.\n",
      "|  To disable this behavior, call `register` with `set_global_tracer_provider=False`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Connect notebook to Phoenix\n",
    "tracer_provider = register(project_name=\"LangChain RAG Tracing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the LangChain Instrumentor\n",
    "## There are lot of other tracer-instruments that can be used for more detailed tracing - https://github.com/Arize-ai/openinference/tree/main/python/instrumentation/openinference-instrumentation-langchain/examples\n",
    "LangChainInstrumentor().instrument(tracer_provider=tracer_provider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Models\n",
    "google_llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-flash-002\",\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "google_llm_embeddings = GoogleGenerativeAIEmbeddings(\n",
    "    model='models/text-embedding-004',\n",
    "    task_type=\"retrieval_document\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FAISS Database Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping Federal Documents\n",
    "def fetch_federal_document(url, div_class):\n",
    "    \"\"\"\n",
    "    Scrapes the transcript of the Act Establishing Yellowstone National Park from the given URL.\n",
    "\n",
    "    Args:\n",
    "    url (str): URL of the webpage to scrape.\n",
    "\n",
    "    Returns:\n",
    "    str: The transcript text of the Act.\n",
    "    \"\"\"\n",
    "    # Sending a request to the URL\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        # Parsing the HTML content of the page\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "        # Finding the transcript section by its HTML structure\n",
    "        transcript_section = soup.find(\"div\", class_=div_class)\n",
    "        if transcript_section:\n",
    "            transcript_text = transcript_section.get_text(separator=\"\\n\", strip=True)\n",
    "            return transcript_text\n",
    "        else:\n",
    "            return \"Transcript section not found.\"\n",
    "    else:\n",
    "        return f\"Failed to retrieve the webpage. Status code: {response.status_code}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Document Fetching and Saving\n",
    "def fetch_and_save_documents(url_list, doc_path):\n",
    "    \"\"\"\n",
    "    Fetches documents from given URLs and saves them to a specified file path.\n",
    "\n",
    "    Args:\n",
    "        url_list (list): List of URLs to fetch documents from.\n",
    "        doc_path (str): Path to the file where documents will be saved.\n",
    "    \"\"\"\n",
    "    for url in url_list:\n",
    "        document = fetch_federal_document(url, \"col-sm-9\")\n",
    "        with open(doc_path, \"a\") as file:\n",
    "            file.write(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FAISS Database Creation\n",
    "def create_faiss_database(document_path, database_save_directory, chunk_size=1500, chunk_overlap=200):\n",
    "    \"\"\"\n",
    "    Creates and saves a FAISS database using documents from the specified file.\n",
    "\n",
    "    Args:\n",
    "        document_path (str): Path to the file containing documents.\n",
    "        database_save_directory (str): Directory where the FAISS database will be saved.\n",
    "        chunk_size (int, optional): Size of each document chunk. Default is 500.\n",
    "        chunk_overlap (int, optional): Overlap between consecutive chunks. Default is 10.\n",
    "\n",
    "    Returns:\n",
    "        FAISS database instance.\n",
    "    \"\"\"\n",
    "    # Load documents from the specified file\n",
    "    document_loader = TextLoader(document_path)\n",
    "    raw_documents = document_loader.load()\n",
    "\n",
    "    # Split documents into smaller chunks with specified size and overlap\n",
    "    document_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "    document_chunks = document_splitter.split_documents(raw_documents)\n",
    "\n",
    "    # Generate embeddings for each document chunk\n",
    "    embedding_generator = google_llm_embeddings\n",
    "    faiss_database = FAISS.from_documents(document_chunks, embedding_generator)\n",
    "\n",
    "    # Save the FAISS database to the specified directory\n",
    "    faiss_database.save_local(database_save_directory)\n",
    "\n",
    "    return faiss_database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a temporary directory to store documents\n",
    "directory = Path('..', 'data')\n",
    "\n",
    "# Document Paths and FAISS Index Directory\n",
    "doc_path = os.path.join(directory, \"docs.txt\")\n",
    "persist_dir = os.path.join(directory, \"faiss_index_langchain_simple_rag\")\n",
    "\n",
    "# URLs of the Federal documents to scrape\n",
    "url_listings = [\n",
    "    \"https://www.archives.gov/milestone-documents/act-establishing-yellowstone-national-park#transcript\",\n",
    "    \"https://www.archives.gov/milestone-documents/sherman-anti-trust-act#transcript\",\n",
    "]\n",
    "\n",
    "# Fetch and save documents from the URLs\n",
    "if not os.path.exists(doc_path):\n",
    "    print(\"Fetching and saving documents...\")\n",
    "    fetch_and_save_documents(url_listings, doc_path)\n",
    "\n",
    "# Create a FAISS database from the saved documents\n",
    "faiss_index = create_faiss_database(doc_path, persist_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Demo Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_formatted_response(response_list, max_line_length=80):\n",
    "    \"\"\"\n",
    "    Formats and prints responses with a maximum line length for better readability.\n",
    "\n",
    "    Args:\n",
    "    response_list (list): A list of strings representing responses.\n",
    "    max_line_length (int): Maximum number of characters in a line. Defaults to 80.\n",
    "    \"\"\"\n",
    "    for response in response_list:\n",
    "        words = response.split()\n",
    "        line = \"\"\n",
    "        for word in words:\n",
    "            if len(line) + len(word) + 1 <= max_line_length:\n",
    "                line += word + \" \"\n",
    "            else:\n",
    "                print(line)\n",
    "                line = word + \" \"\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup RetrievalQA\n",
    "retrievalQA = RetrievalQA.from_llm(llm=google_llm, retriever=faiss_index.as_retriever())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The document states that anyone settling, locating, or occupying the land set \n",
      "apart as a public park (except as otherwise provided) will be considered a \n",
      "trespasser and removed. Another section says that the Secretary of the Interior \n",
      "shall cause all persons trespassing on the park after the passage of the act to \n",
      "be removed. \n"
     ]
    }
   ],
   "source": [
    "answer1 = retrievalQA.invoke({\"query\": \"What does the document say about trespassers?\"})\n",
    "\n",
    "print_formatted_response([answer1['result']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided text, a bridle-path is a path suitable for riding horses. \n",
      "The text mentions that the Secretary of the Interior is to construct roads and \n",
      "bridle-paths in Yellowstone National Park. However, whether or not you can \n",
      "currently use one is not specified in these documents. \n"
     ]
    }
   ],
   "source": [
    "answer2 = retrievalQA.invoke({\"query\": \"What is a bridle-path and can I use one at Yellowstone?\"})\n",
    "\n",
    "print_formatted_response([answer2['result']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't know. The provided text describes the establishment of Yellowstone \n",
      "National Park and its management, but it doesn't contain information about the \n",
      "possibility of purchasing the park from the federal government. \n"
     ]
    }
   ],
   "source": [
    "answer3 = retrievalQA.invoke({\"query\": \"Can I buy Yellowstone from the Federal Government to set up a buffalo-themed day spa?\"})\n",
    "\n",
    "print_formatted_response([answer3['result']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chat with RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "contextualize_q_system_prompt = (\n",
    "    \"Given a chat history and the latest user question \"\n",
    "    \"which might reference context in the chat history, \"\n",
    "    \"formulate a standalone question which can be understood \"\n",
    "    \"without the chat history. Do NOT answer the question, \"\n",
    "    \"just reformulate it if needed and otherwise return it as is.\"\n",
    ")\n",
    "\n",
    "contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", contextualize_q_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_aware_retriever = create_history_aware_retriever(\n",
    "    google_llm, faiss_index.as_retriever(), contextualize_q_prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = (\n",
    "    \"You are an assistant for question-answering tasks. \"\n",
    "    \"Use the following pieces of retrieved context to answer \"\n",
    "    \"the question. If you don't know the answer, say that you \"\n",
    "    \"don't know. Use three sentences maximum and keep the \"\n",
    "    \"answer concise.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "qa_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_answer_chain = create_stuff_documents_chain(google_llm, qa_prompt)\n",
    "rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The document describes an act passed by the 42nd Congress establishing \n",
      "Yellowstone National Park. It designates a specific tract of land near the \n",
      "Yellowstone River's headwaters as a public park, reserving it from settlement \n",
      "and sale. The act also outlines the Secretary of the Interior's \n",
      "responsibilities for managing the park, including preserving its natural \n",
      "resources and regulating visitor access. \n"
     ]
    }
   ],
   "source": [
    "chat_history = []\n",
    "question = \"What is the document say about the Yellowstone?\"\n",
    "ai_msg_1 = rag_chain.invoke({\"input\": question, \"chat_history\": chat_history})\n",
    "print_formatted_response([ai_msg_1['answer']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No, the document explicitly states that the land described is \"reserved and \n",
      "withdrawn from settlement, occupancy, or sale under the laws of the United \n",
      "States\". \n"
     ]
    }
   ],
   "source": [
    "chat_history.extend(\n",
    "    [\n",
    "        HumanMessage(content=question),\n",
    "        AIMessage(content=ai_msg_1[\"answer\"]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "second_question = \"Can I buy it from the Fedral Government?\"\n",
    "ai_msg_2 = rag_chain.invoke({\"input\": second_question, \"chat_history\": chat_history})\n",
    "\n",
    "print_formatted_response([ai_msg_2[\"answer\"]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLMObs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
